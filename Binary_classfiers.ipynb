{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv  \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Eclipse_JDT = pd.read_csv('Eclipse_ JDT_Core_single-version-ck-oo_bugs_only.csv', error_bad_lines=False)\n",
    "Eclipse_PDE = pd.read_csv('Eclipse_PDE_UI_single-version-ck-oo_bug_only.csv', error_bad_lines=False)\n",
    "Equinox = pd.read_csv('Equinox_Framework_single-version-ck-oo_bug_only.csv', error_bad_lines=False)\n",
    "Lucene = pd.read_csv('Lucene_single-version-ck-oo_bug_only.csv', error_bad_lines=False)\n",
    "Mylyn = pd.read_csv('Mylyn_single-version-ck-oo_bug_only.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "### first dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Eclipse_ JDT_Core_single-version-ck-oo_bugs_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Eclipse_JDT.values[i-1][18]) \n",
    "    train_data.append(Eclipse_JDT.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "        \n",
    "trainx_1, tempx, trainy_1, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_1, valx_1, testy_1, valy_1 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_1 = np.array(trainx_1)\n",
    "trainy_1 = np.array(trainy_1)\n",
    "testx_1 = np.array(testx_1)\n",
    "testy_1 = np.array(testy_1)\n",
    "valx_1 = np.array(valx_1)\n",
    "valy_1 = np.array(valy_1)\n",
    "    \n",
    "    ### second dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Eclipse_PDE_UI_single-version-ck-oo_bug_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Eclipse_PDE.values[i-1][18]) \n",
    "    train_data.append(Eclipse_PDE.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "\n",
    "trainx_2, tempx, trainy_2, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_2, valx_2, testy_2, valy_2 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_2 = np.array(trainx_2)\n",
    "trainy_2 = np.array(trainy_2)\n",
    "testx_2 = np.array(testx_2)\n",
    "testy_2 = np.array(testy_2)\n",
    "valx_2 = np.array(valx_2)\n",
    "valy_2 = np.array(valy_2)\n",
    "    \n",
    "    ### third dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Equinox_Framework_single-version-ck-oo_bug_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Equinox.values[i-1][18]) \n",
    "    train_data.append(Equinox.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "\n",
    "trainx_3, tempx, trainy_3, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_3, valx_3, testy_3, valy_3 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_3 = np.array(trainx_3)\n",
    "trainy_3 = np.array(trainy_3)\n",
    "testx_3 = np.array(testx_3)\n",
    "testy_3 = np.array(testy_3)\n",
    "valx_3 = np.array(valx_3)\n",
    "valy_3 = np.array(valy_3)\n",
    "    \n",
    "    ### fourth dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Lucene_single-version-ck-oo_bug_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Lucene.values[i-1][18]) \n",
    "    train_data.append(Lucene.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "  \n",
    "trainx_4, tempx, trainy_4, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_4, valx_4, testy_4, valy_4 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_4 = np.array(trainx_4)\n",
    "trainy_4 = np.array(trainy_4)\n",
    "testx_4 = np.array(testx_4)\n",
    "testy_4 = np.array(testy_4)\n",
    "valx_4 = np.array(valx_4)\n",
    "valy_4 = np.array(valy_4)\n",
    "    \n",
    "    ### fifth dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Mylyn_single-version-ck-oo_bug_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Mylyn.values[i-1][18]) \n",
    "    train_data.append(Mylyn.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "  \n",
    "trainx_5, tempx, trainy_5, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_5, valx_5, testy_5, valy_5 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_5 = np.array(trainx_5)\n",
    "trainy_5 = np.array(trainy_5)\n",
    "testx_5 = np.array(testx_5)\n",
    "testy_5 = np.array(testy_5)\n",
    "valx_5 = np.array(valx_5)\n",
    "valy_5 = np.array(valy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we divide the target set into three classes, 0, and 1 #\n",
    "\n",
    "###first data set ###\n",
    "\n",
    "for i in range(len(trainy_1)):\n",
    "    if (trainy_1[i] > 1):\n",
    "        trainy_1[i] = 1\n",
    "\n",
    "for i in range(len(testy_1)):\n",
    "    if (testy_1[i] > 1):\n",
    "        testy_1[i] = 1\n",
    "        \n",
    "for i in range(len(valy_1)):\n",
    "    if (valy_1[i] > 1):\n",
    "        valy_1[i] = 1\n",
    "\n",
    "### second data set ###\n",
    "\n",
    "for i in range(len(trainy_2)):\n",
    "    if (trainy_2[i] > 1):\n",
    "        trainy_2[i] = 1\n",
    "\n",
    "for i in range(len(testy_2)):\n",
    "    if (testy_2[i] > 1):\n",
    "        testy_2[i] = 1\n",
    "        \n",
    "for i in range(len(valy_2)):\n",
    "    if (valy_2[i] > 1):\n",
    "        valy_2[i] = 1\n",
    "        \n",
    "### third data set ###\n",
    "        \n",
    "for i in range(len(trainy_3)):\n",
    "    if (trainy_3[i] > 1):\n",
    "        trainy_3[i] = 1\n",
    "\n",
    "for i in range(len(testy_3)):\n",
    "    if (testy_3[i] > 1):\n",
    "        testy_3[i] = 1\n",
    "        \n",
    "for i in range(len(valy_3)):\n",
    "    if (valy_3[i] > 1):\n",
    "        valy_3[i] = 1\n",
    "        \n",
    "### forth data set ###\n",
    "        \n",
    "for i in range(len(trainy_4)):\n",
    "    if (trainy_4[i] > 1):\n",
    "        trainy_4[i] = 1\n",
    "\n",
    "for i in range(len(testy_4)):\n",
    "    if (testy_4[i] > 1):\n",
    "        testy_4[i] = 1\n",
    "        \n",
    "for i in range(len(valy_4)):\n",
    "    if (valy_4[i] > 1):\n",
    "        valy_4[i] = 1\n",
    "        \n",
    "### fifth data set ###\n",
    "        \n",
    "for i in range(len(trainy_5)):\n",
    "    if (trainy_5[i] > 1):\n",
    "        trainy_5[i] = 1\n",
    "\n",
    "for i in range(len(testy_5)):\n",
    "    if (testy_5[i] > 1):\n",
    "        testy_5[i] = 1\n",
    "        \n",
    "for i in range(len(valy_5)):\n",
    "    if (valy_5[i] > 1):\n",
    "        valy_5[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "### down below i will construct a complete model for the KNN and tg=hen we can use it to classify our data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1304, 17)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(trainx_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2distance(x,y):\n",
    "    return np.sum(np.square(x-y))\n",
    "\n",
    "def nearestNeighbor(x,trainx,trainy): \n",
    "    distance = [L2distance(x,trainx[i,]) for i in range (len(trainy))]\n",
    "    label = trainy[np.argmin(distance)] \n",
    "    return label\n",
    "\n",
    "def NN_L2(trainx, trainy, evalx):\n",
    "    result = []\n",
    "    for i in range(len(evalx)):\n",
    "        result.append(nearestNeighbor(evalx[i],trainx,trainy))\n",
    "    \n",
    "    return result\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics \n",
    "from statistics import mode \n",
    "\n",
    "def KnearestNeighbor(x,trainx,trainy,k): \n",
    "    distance = [L2distance(x,trainx[i,]) for i in range (len(trainy))]\n",
    "    Neighbors = np.argpartition(distance,k)\n",
    "    NeighborsLabels = []\n",
    "   \n",
    "    for c in range(k):\n",
    "      NeighborsLabels.append(trainy[Neighbors[c]])\n",
    "\n",
    "    return votes(NeighborsLabels)\n",
    "\n",
    "def votes(Neighbors):\n",
    "    count = []\n",
    "    num = -100 \n",
    "      \n",
    "    for i in Neighbors:\n",
    "        if (i > 0):\n",
    "            count.append(1)\n",
    "        else:\n",
    "            count.append(0)\n",
    "            \n",
    "        #curr_frequency = Neighbors.count(i) \n",
    "        #if(curr_frequency > counter): \n",
    "         #   counter = curr_frequency \n",
    "          #  num = i \n",
    "    \n",
    "    counts = np.bincount(count)\n",
    "    num = np.argmax(counts)\n",
    "    return num \n",
    "  \n",
    " \n",
    "\n",
    "def KNN_L2(trainx, trainy, evalx, K):\n",
    "    results = []\n",
    "    for i in range(len(evalx)):\n",
    "        results.append(KnearestNeighbor(evalx[i],trainx,trainy,K))\n",
    "    \n",
    "    return results\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1distance(x,y):\n",
    "  return np.linalg.norm(x - y, ord=1)\n",
    "\n",
    "\n",
    "def nearestNeighborL1(x,trainx,trainy): \n",
    "    distance = [L1distance(x,trainx[i,]) for i in range (len(trainy))]\n",
    "    label = trainy[np.argmin(distance)] \n",
    "    return label\n",
    "  \n",
    "def NN_L1(trainx, trainy, evalx):\n",
    "    result = []\n",
    "    for i in range(len(evalx)):\n",
    "        result.append(nearestNeighborL1(evalx[i],trainx,trainy))\n",
    "    \n",
    "    return result\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KnearestNeighborL1(x,trainx,trainy,k): \n",
    "    distance = [L1distance(x,trainx[i,]) for i in range (len(trainy))]\n",
    "    Neighbors = np.argpartition(distance,k)\n",
    "    NeighborsLabels = []\n",
    "   \n",
    "    for c in range(k):\n",
    "      NeighborsLabels.append(trainy[Neighbors[c]])\n",
    "\n",
    "    return votesL1(NeighborsLabels)\n",
    "\n",
    "def votesL1(Neighbors):\n",
    "    counter = 0\n",
    "    num = Neighbors[0] \n",
    "      \n",
    "    for i in Neighbors: \n",
    "        curr_frequency = Neighbors.count(i) \n",
    "        if(curr_frequency> counter): \n",
    "            counter = curr_frequency \n",
    "            num = i \n",
    "            \n",
    "    return num \n",
    "  \n",
    " \n",
    "\n",
    "def KNN_L1(trainx, trainy, evalx, K):\n",
    "    results = []\n",
    "    for i in range(len(evalx)):\n",
    "        results.append(KnearestNeighborL1(evalx[i],trainx,trainy,K))\n",
    "    \n",
    "    return results\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(trainx, trainy, evalx, K, dist_metric):\n",
    "    if dist_metric == 2:\n",
    "        return KNN_L2(trainx, trainy, evalx, K)\n",
    "    else:\n",
    "        return KNN_L1(trainx, trainy, evalx, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satrt\n",
      "error rate for k = 1 is 0.2\n",
      "error rate for k = 2 is 0.20666666666666667\n",
      "error rate for k = 3 is 0.18666666666666668\n",
      "error rate for k = 4 is 0.19333333333333333\n",
      "error rate for k = 5 is 0.16666666666666666\n",
      "error rate for k = 6 is 0.16666666666666666\n",
      "error rate for k = 7 is 0.16\n",
      "error rate for k = 8 is 0.17333333333333334\n",
      "error rate for k = 9 is 0.16666666666666666\n",
      "error rate for k = 10 is 0.16666666666666666\n",
      "error rate for k = 11 is 0.16666666666666666\n",
      "error rate for k = 12 is 0.16\n",
      "error rate for k = 13 is 0.17333333333333334\n",
      "error rate for k = 14 is 0.16\n",
      "error rate for k = 15 is 0.16666666666666666\n",
      "error rate for k = 16 is 0.18\n",
      "error rate for k = 17 is 0.18\n",
      "error rate for k = 18 is 0.18\n",
      "error rate for k = 19 is 0.18\n",
      "error rate for k = 20 is 0.18\n",
      "error rate for k = 21 is 0.18\n",
      "error rate for k = 22 is 0.16666666666666666\n",
      "error rate for k = 23 is 0.16666666666666666\n",
      "error rate for k = 24 is 0.17333333333333334\n",
      "error rate for k = 25 is 0.17333333333333334\n",
      "error rate for k = 26 is 0.17333333333333334\n",
      "error rate for k = 27 is 0.16666666666666666\n",
      "error rate for k = 28 is 0.17333333333333334\n",
      "error rate for k = 29 is 0.16666666666666666\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "values_1 = []\n",
    "values_1 = np.array(values)\n",
    "print(\"satrt\")\n",
    "for k in range(1,30):\n",
    "    values_1 = KNN(trainx_1, trainy_1, valx_1, int(k), int(2))\n",
    "    error_rate = np.mean(values_1 != valy_1)\n",
    "    print(f\"error rate for k = {k} is {error_rate}\")\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satrt\n",
      "error rate for k = 1 is 0.21333333333333335\n",
      "error rate for k = 2 is 0.12\n",
      "error rate for k = 3 is 0.14222222222222222\n",
      "error rate for k = 4 is 0.12444444444444444\n",
      "error rate for k = 5 is 0.12444444444444444\n",
      "error rate for k = 6 is 0.11555555555555555\n",
      "error rate for k = 7 is 0.10222222222222223\n",
      "error rate for k = 8 is 0.10666666666666667\n",
      "error rate for k = 9 is 0.10666666666666667\n",
      "error rate for k = 10 is 0.12\n",
      "error rate for k = 11 is 0.12\n",
      "error rate for k = 12 is 0.12\n",
      "error rate for k = 13 is 0.12\n",
      "error rate for k = 14 is 0.11555555555555555\n",
      "error rate for k = 15 is 0.11555555555555555\n",
      "error rate for k = 16 is 0.11555555555555555\n",
      "error rate for k = 17 is 0.12\n",
      "error rate for k = 18 is 0.1111111111111111\n",
      "error rate for k = 19 is 0.11555555555555555\n",
      "error rate for k = 20 is 0.12\n",
      "error rate for k = 21 is 0.12444444444444444\n",
      "error rate for k = 22 is 0.12444444444444444\n",
      "error rate for k = 23 is 0.12\n",
      "error rate for k = 24 is 0.12\n",
      "error rate for k = 25 is 0.12\n",
      "error rate for k = 26 is 0.12\n",
      "error rate for k = 27 is 0.12\n",
      "error rate for k = 28 is 0.12\n",
      "error rate for k = 29 is 0.12\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "values_2 = []\n",
    "values_2 = np.array(values)\n",
    "print(\"satrt\")\n",
    "for k in range(1,30):\n",
    "    values_2 = KNN(trainx_2, trainy_2, valx_2, int(k), int(2))\n",
    "    error_rate = np.mean(values_2 != valy_2)\n",
    "    print(f\"error rate for k = {k} is {error_rate}\")\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satrt\n",
      "error rate for k = 1 is 0.30612244897959184\n",
      "error rate for k = 2 is 0.2857142857142857\n",
      "error rate for k = 3 is 0.30612244897959184\n",
      "error rate for k = 4 is 0.30612244897959184\n",
      "error rate for k = 5 is 0.2653061224489796\n",
      "error rate for k = 6 is 0.2857142857142857\n",
      "error rate for k = 7 is 0.3673469387755102\n",
      "error rate for k = 8 is 0.3877551020408163\n",
      "error rate for k = 9 is 0.3469387755102041\n",
      "error rate for k = 10 is 0.32653061224489793\n",
      "error rate for k = 11 is 0.3673469387755102\n",
      "error rate for k = 12 is 0.3877551020408163\n",
      "error rate for k = 13 is 0.3469387755102041\n",
      "error rate for k = 14 is 0.3469387755102041\n",
      "error rate for k = 15 is 0.3469387755102041\n",
      "error rate for k = 16 is 0.3469387755102041\n",
      "error rate for k = 17 is 0.3877551020408163\n",
      "error rate for k = 18 is 0.3877551020408163\n",
      "error rate for k = 19 is 0.3877551020408163\n",
      "error rate for k = 20 is 0.3673469387755102\n",
      "error rate for k = 21 is 0.3877551020408163\n",
      "error rate for k = 22 is 0.3469387755102041\n",
      "error rate for k = 23 is 0.3469387755102041\n",
      "error rate for k = 24 is 0.32653061224489793\n",
      "error rate for k = 25 is 0.3673469387755102\n",
      "error rate for k = 26 is 0.3469387755102041\n",
      "error rate for k = 27 is 0.3877551020408163\n",
      "error rate for k = 28 is 0.3877551020408163\n",
      "error rate for k = 29 is 0.3673469387755102\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "values_3 = []\n",
    "values_3 = np.array(values)\n",
    "print(\"satrt\")\n",
    "for k in range(1,30):\n",
    "    values_3 = KNN(trainx_3, trainy_3, valx_3, int(k), int(2))\n",
    "    error_rate = np.mean(values_3 != valy_3)\n",
    "    print(f\"error rate for k = {k} is {error_rate}\")\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satrt\n",
      "error rate for k = 1 is 0.0673076923076923\n",
      "error rate for k = 2 is 0.07692307692307693\n",
      "error rate for k = 3 is 0.0673076923076923\n",
      "error rate for k = 4 is 0.07692307692307693\n",
      "error rate for k = 5 is 0.07692307692307693\n",
      "error rate for k = 6 is 0.07692307692307693\n",
      "error rate for k = 7 is 0.07692307692307693\n",
      "error rate for k = 8 is 0.07692307692307693\n",
      "error rate for k = 9 is 0.07692307692307693\n",
      "error rate for k = 10 is 0.07692307692307693\n",
      "error rate for k = 11 is 0.07692307692307693\n",
      "error rate for k = 12 is 0.07692307692307693\n",
      "error rate for k = 13 is 0.07692307692307693\n",
      "error rate for k = 14 is 0.07692307692307693\n",
      "error rate for k = 15 is 0.07692307692307693\n",
      "error rate for k = 16 is 0.07692307692307693\n",
      "error rate for k = 17 is 0.07692307692307693\n",
      "error rate for k = 18 is 0.07692307692307693\n",
      "error rate for k = 19 is 0.07692307692307693\n",
      "error rate for k = 20 is 0.07692307692307693\n",
      "error rate for k = 21 is 0.07692307692307693\n",
      "error rate for k = 22 is 0.07692307692307693\n",
      "error rate for k = 23 is 0.07692307692307693\n",
      "error rate for k = 24 is 0.07692307692307693\n",
      "error rate for k = 25 is 0.07692307692307693\n",
      "error rate for k = 26 is 0.07692307692307693\n",
      "error rate for k = 27 is 0.07692307692307693\n",
      "error rate for k = 28 is 0.07692307692307693\n",
      "error rate for k = 29 is 0.07692307692307693\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "values_4 = []\n",
    "values_4 = np.array(values)\n",
    "print(\"satrt\")\n",
    "for k in range(1,30):\n",
    "    values_4 = KNN(trainx_4, trainy_4, valx_4, int(k), int(2))\n",
    "    error_rate = np.mean(values_4 != valy_4)\n",
    "    print(f\"error rate for k = {k} is {error_rate}\")\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "satrt\n",
      "error rate for k = 1 is 0.15\n",
      "error rate for k = 2 is 0.10357142857142858\n",
      "error rate for k = 3 is 0.1357142857142857\n",
      "error rate for k = 4 is 0.12857142857142856\n",
      "error rate for k = 5 is 0.12142857142857143\n",
      "error rate for k = 6 is 0.12142857142857143\n",
      "error rate for k = 7 is 0.14285714285714285\n",
      "error rate for k = 8 is 0.13214285714285715\n",
      "error rate for k = 9 is 0.12857142857142856\n",
      "error rate for k = 10 is 0.13214285714285715\n",
      "error rate for k = 11 is 0.1357142857142857\n",
      "error rate for k = 12 is 0.12857142857142856\n",
      "error rate for k = 13 is 0.12857142857142856\n",
      "error rate for k = 14 is 0.12857142857142856\n",
      "error rate for k = 15 is 0.13214285714285715\n",
      "error rate for k = 16 is 0.12857142857142856\n",
      "error rate for k = 17 is 0.13214285714285715\n",
      "error rate for k = 18 is 0.125\n",
      "error rate for k = 19 is 0.125\n",
      "error rate for k = 20 is 0.12142857142857143\n",
      "error rate for k = 21 is 0.12142857142857143\n",
      "error rate for k = 22 is 0.11071428571428571\n",
      "error rate for k = 23 is 0.11428571428571428\n",
      "error rate for k = 24 is 0.11071428571428571\n",
      "error rate for k = 25 is 0.11428571428571428\n",
      "error rate for k = 26 is 0.11071428571428571\n",
      "error rate for k = 27 is 0.11071428571428571\n",
      "error rate for k = 28 is 0.10714285714285714\n",
      "error rate for k = 29 is 0.10714285714285714\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "values_5 = []\n",
    "values_5 = np.array(values)\n",
    "print(\"satrt\")\n",
    "for k in range(1,30):\n",
    "    values_5 = KNN(trainx_5, trainy_5, valx_5, int(k), int(2))\n",
    "    error_rate = np.mean(values_5 != valy_5)\n",
    "    print(f\"error rate for k = {k} is {error_rate}\")\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classfier two ###\n",
    "### down below i will construct a complete model for the LR and tg=hen we can use it to classify our data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    s = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    " \n",
    "    w = np.zeros([dim,1])\n",
    "    b = 0\n",
    "\n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    " \n",
    "    m = X.shape[1]\n",
    "  \n",
    "    z=np.dot(w.T,X)+b                                  \n",
    "    A = sigmoid(z)\n",
    "    first_part=np.dot(Y,np.log(A).T)\n",
    "    second_part=np.dot((1-Y),np.log(1-A).T)\n",
    "    cost = -1/m *(first_part+second_part)\n",
    "    \n",
    "    dw = 1 / m *np.dot(X,(A-Y).T)\n",
    "    db = 1 / m *np.sum(A-Y)\n",
    "\n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "  \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "   \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w-learning_rate*dw\n",
    "        b = b-learning_rate*db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    z = np.dot(w.T,X) + b                                   \n",
    "    A = sigmoid(z)\n",
    "\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        if A[0,i] >0.5:\n",
    "            Y_prediction[0,i]=1\n",
    "        elif  A[0,i] <=0.5:\n",
    "            Y_prediction[0,i]=0\n",
    "        pass\n",
    "     \n",
    "    \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
    "\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.522251\n",
      "Cost after iteration 200: 0.502882\n",
      "Cost after iteration 300: 0.499814\n",
      "Cost after iteration 400: 0.499236\n",
      "Cost after iteration 500: 0.499103\n",
      "Cost after iteration 600: 0.499055\n",
      "Cost after iteration 700: 0.499023\n",
      "Cost after iteration 800: 0.498995\n",
      "Cost after iteration 900: 0.498968\n",
      "Cost after iteration 1000: 0.498940\n",
      "Cost after iteration 1100: 0.498913\n",
      "Cost after iteration 1200: 0.498886\n",
      "Cost after iteration 1300: 0.498859\n",
      "Cost after iteration 1400: 0.498832\n",
      "Cost after iteration 1500: 0.498805\n",
      "Cost after iteration 1600: 0.498778\n",
      "Cost after iteration 1700: 0.498752\n",
      "Cost after iteration 1800: 0.498725\n",
      "Cost after iteration 1900: 0.498698\n",
      "train accuracy: 80.08595988538681 %\n",
      "test accuracy: 80.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainx_1 = trainx_1.astype(float)\n",
    "testx_1 = testx_1.astype(float)\n",
    "\n",
    "trainx_1 = np.reshape(trainx_1, (17,698)) \n",
    "testx_1 = np.reshape(testx_1, (17, 150)) \n",
    "trainy_1 = np.reshape(trainy_1, (1, 698)) \n",
    "testy_1 = np.reshape(testy_1, (1, 150)) \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "trainx_1 = preprocessing.normalize(trainx_1)\n",
    "testx_1 = preprocessing.normalize(testx_1)\n",
    "\n",
    "LR = model(trainx_1, trainy_1, testx_1, testy_1, num_iterations = 2000, learning_rate = 0.05, print_cost = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.635775\n",
      "Cost after iteration 200: 0.591030\n",
      "Cost after iteration 300: 0.555982\n",
      "Cost after iteration 400: 0.528364\n",
      "Cost after iteration 500: 0.506452\n",
      "Cost after iteration 600: 0.488941\n",
      "Cost after iteration 700: 0.474848\n",
      "Cost after iteration 800: 0.463428\n",
      "Cost after iteration 900: 0.454112\n",
      "Cost after iteration 1000: 0.446466\n",
      "Cost after iteration 1100: 0.440155\n",
      "Cost after iteration 1200: 0.434918\n",
      "Cost after iteration 1300: 0.430552\n",
      "Cost after iteration 1400: 0.426895\n",
      "Cost after iteration 1500: 0.423819\n",
      "Cost after iteration 1600: 0.421222\n",
      "Cost after iteration 1700: 0.419022\n",
      "Cost after iteration 1800: 0.417152\n",
      "Cost after iteration 1900: 0.415558\n",
      "train accuracy: 85.97328244274809 %\n",
      "test accuracy: 84.44444444444444 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainx_2 = trainx_2.astype(float)\n",
    "testx_2 = testx_2.astype(float)\n",
    "\n",
    "trainx_2 = np.reshape(trainx_2, (17,1048)) \n",
    "testx_2 = np.reshape(testx_2, (17, 225)) \n",
    "trainy_2 = np.reshape(trainy_2, (1, 1048)) \n",
    "testy_2 = np.reshape(testy_2, (1, 225)) \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "trainx_2 = preprocessing.normalize(trainx_2)\n",
    "testx_2 = preprocessing.normalize(testx_2)\n",
    "\n",
    "LR = model(trainx_2, trainy_2, testx_2, testy_2, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.688750\n",
      "Cost after iteration 200: 0.685322\n",
      "Cost after iteration 300: 0.682647\n",
      "Cost after iteration 400: 0.680557\n",
      "Cost after iteration 500: 0.678921\n",
      "Cost after iteration 600: 0.677638\n",
      "Cost after iteration 700: 0.676629\n",
      "Cost after iteration 800: 0.675834\n",
      "Cost after iteration 900: 0.675205\n",
      "Cost after iteration 1000: 0.674706\n",
      "Cost after iteration 1100: 0.674308\n",
      "Cost after iteration 1200: 0.673988\n",
      "Cost after iteration 1300: 0.673730\n",
      "Cost after iteration 1400: 0.673520\n",
      "Cost after iteration 1500: 0.673347\n",
      "Cost after iteration 1600: 0.673204\n",
      "Cost after iteration 1700: 0.673084\n",
      "Cost after iteration 1800: 0.672982\n",
      "Cost after iteration 1900: 0.672894\n",
      "train accuracy: 59.91189427312775 %\n",
      "test accuracy: 53.06122448979592 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainx_3 = trainx_3.astype(float)\n",
    "testx_3 = testx_3.astype(float)\n",
    "\n",
    "trainx_3 = np.reshape(trainx_3, (17,227)) \n",
    "testx_3 = np.reshape(testx_3, (17, 49)) \n",
    "trainy_3 = np.reshape(trainy_3, (1, 227)) \n",
    "testy_3 = np.reshape(testy_3, (1, 49)) \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "trainx_3 = preprocessing.normalize(trainx_3)\n",
    "testx_3 = preprocessing.normalize(testx_3)\n",
    "\n",
    "LR = model(trainx_3, trainy_3, testx_3, testy_3, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.615866\n",
      "Cost after iteration 200: 0.555568\n",
      "Cost after iteration 300: 0.508246\n",
      "Cost after iteration 400: 0.470812\n",
      "Cost after iteration 500: 0.440930\n",
      "Cost after iteration 600: 0.416855\n",
      "Cost after iteration 700: 0.397278\n",
      "Cost after iteration 800: 0.381219\n",
      "Cost after iteration 900: 0.367935\n",
      "Cost after iteration 1000: 0.356861\n",
      "Cost after iteration 1100: 0.347564\n",
      "Cost after iteration 1200: 0.339707\n",
      "Cost after iteration 1300: 0.333025\n",
      "Cost after iteration 1400: 0.327313\n",
      "Cost after iteration 1500: 0.322403\n",
      "Cost after iteration 1600: 0.318163\n",
      "Cost after iteration 1700: 0.314486\n",
      "Cost after iteration 1800: 0.311283\n",
      "Cost after iteration 1900: 0.308485\n",
      "train accuracy: 91.73553719008264 %\n",
      "test accuracy: 84.61538461538461 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainx_4 = trainx_4.astype(float)\n",
    "testx_4 = testx_4.astype(float)\n",
    "\n",
    "trainx_4 = np.reshape(trainx_4, (17,484)) \n",
    "testx_4 = np.reshape(testx_4, (17, 104)) \n",
    "trainy_4 = np.reshape(trainy_4, (1, 484)) \n",
    "testy_4 = np.reshape(testy_4, (1, 104)) \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "trainx_4 = preprocessing.normalize(trainx_4)\n",
    "testx_4 = preprocessing.normalize(testx_4)\n",
    "\n",
    "LR = model(trainx_4, trainy_4, testx_4, testy_4, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 100: 0.635831\n",
      "Cost after iteration 200: 0.591125\n",
      "Cost after iteration 300: 0.556101\n",
      "Cost after iteration 400: 0.528499\n",
      "Cost after iteration 500: 0.506597\n",
      "Cost after iteration 600: 0.489093\n",
      "Cost after iteration 700: 0.475004\n",
      "Cost after iteration 800: 0.463586\n",
      "Cost after iteration 900: 0.454271\n",
      "Cost after iteration 1000: 0.446625\n",
      "Cost after iteration 1100: 0.440315\n",
      "Cost after iteration 1200: 0.435078\n",
      "Cost after iteration 1300: 0.430711\n",
      "Cost after iteration 1400: 0.427053\n",
      "Cost after iteration 1500: 0.423977\n",
      "Cost after iteration 1600: 0.421379\n",
      "Cost after iteration 1700: 0.419179\n",
      "Cost after iteration 1800: 0.417309\n",
      "Cost after iteration 1900: 0.415715\n",
      "train accuracy: 85.96625766871166 %\n",
      "test accuracy: 88.5304659498208 %\n"
     ]
    }
   ],
   "source": [
    "trainx_5 = trainx_5.astype(float)\n",
    "testx_5 = testx_5.astype(float)\n",
    "\n",
    "trainx_5 = np.reshape(trainx_5, (17,1304)) \n",
    "testx_5 = np.reshape(testx_5, (17, 279)) \n",
    "trainy_5 = np.reshape(trainy_5, (1, 1304)) \n",
    "testy_5 = np.reshape(testy_5, (1, 279)) \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "trainx_5 = preprocessing.normalize(trainx_5)\n",
    "testx_5 = preprocessing.normalize(testx_5)\n",
    "\n",
    "LR = model(trainx_5, trainy_5, testx_5, testy_5, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
