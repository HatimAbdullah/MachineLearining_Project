{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv  \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eclipse_JDT = pd.read_csv('Eclipse_ JDT_Core_single-version-ck-oo_bugs_only.csv', error_bad_lines=False)\n",
    "Eclipse_PDE = pd.read_csv('Eclipse_PDE_UI_single-version-ck-oo_bug_only.csv', error_bad_lines=False)\n",
    "Equinox = pd.read_csv('Equinox_Framework_single-version-ck-oo_bug_only.csv', error_bad_lines=False)\n",
    "Lucene = pd.read_csv('Lucene_single-version-ck-oo_bug_only.csv', error_bad_lines=False)\n",
    "Mylyn = pd.read_csv('Mylyn_single-version-ck-oo_bug_only.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now we prepare and split the data ###\n",
    "\n",
    "### first dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Eclipse_ JDT_Core_single-version-ck-oo_bugs_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Eclipse_JDT.values[i-1][18]) \n",
    "    train_data.append(Eclipse_JDT.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "        \n",
    "trainx_1, tempx, trainy_1, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_1, valx_1, testy_1, valy_1 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_1 = np.array(trainx_1)\n",
    "trainy_1 = np.array(trainy_1)\n",
    "testx_1 = np.array(testx_1)\n",
    "testy_1 = np.array(testy_1)\n",
    "valx_1 = np.array(valx_1)\n",
    "valy_1 = np.array(valy_1)\n",
    "    \n",
    "    ### second dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Eclipse_PDE_UI_single-version-ck-oo_bug_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Eclipse_PDE.values[i-1][18]) \n",
    "    train_data.append(Eclipse_PDE.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "\n",
    "trainx_2, tempx, trainy_2, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_2, valx_2, testy_2, valy_2 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_2 = np.array(trainx_2)\n",
    "trainy_2 = np.array(trainy_2)\n",
    "testx_2 = np.array(testx_2)\n",
    "testy_2 = np.array(testy_2)\n",
    "valx_2 = np.array(valx_2)\n",
    "valy_2 = np.array(valy_2)\n",
    "    \n",
    "    ### third dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Equinox_Framework_single-version-ck-oo_bug_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Equinox.values[i-1][18]) \n",
    "    train_data.append(Equinox.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "\n",
    "trainx_3, tempx, trainy_3, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_3, valx_3, testy_3, valy_3 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_3 = np.array(trainx_3)\n",
    "trainy_3 = np.array(trainy_3)\n",
    "testx_3 = np.array(testx_3)\n",
    "testy_3 = np.array(testy_3)\n",
    "valx_3 = np.array(valx_3)\n",
    "valy_3 = np.array(valy_3)\n",
    "    \n",
    "    ### fourth dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Lucene_single-version-ck-oo_bug_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Lucene.values[i-1][18]) \n",
    "    train_data.append(Lucene.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "  \n",
    "trainx_4, tempx, trainy_4, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_4, valx_4, testy_4, valy_4 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_4 = np.array(trainx_4)\n",
    "trainy_4 = np.array(trainy_4)\n",
    "testx_4 = np.array(testx_4)\n",
    "testy_4 = np.array(testy_4)\n",
    "valx_4 = np.array(valx_4)\n",
    "valy_4 = np.array(valy_4)\n",
    "    \n",
    "    ### fifth dataset ###\n",
    "    \n",
    "i = 0 \n",
    "train_label = []\n",
    "train_data = []\n",
    "file = csv.reader(open('Mylyn_single-version-ck-oo_bug_only.csv'), delimiter=',')\n",
    "for line in file:\n",
    "    train_label.append(Mylyn.values[i-1][18]) \n",
    "    train_data.append(Mylyn.values[i-1][1:18]) \n",
    "    i = i + 1\n",
    "  \n",
    "trainx_5, tempx, trainy_5, tempy = train_test_split(train_data, train_label, test_size=0.30, random_state=42)\n",
    "testx_5, valx_5, testy_5, valy_5 = train_test_split(tempx, tempy, test_size=0.50, random_state=42)\n",
    "    \n",
    "trainx_5 = np.array(trainx_5)\n",
    "trainy_5 = np.array(trainy_5)\n",
    "testx_5 = np.array(testx_5)\n",
    "testy_5 = np.array(testy_5)\n",
    "valx_5 = np.array(valx_5)\n",
    "valy_5 = np.array(valy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we divide the target set into three classes, 0, 1, and 2 #\n",
    "\n",
    "###first data set ###\n",
    "\n",
    "for i in range(len(trainy_1)):\n",
    "    if (trainy_1[i] > 2):\n",
    "        trainy_1[i] = 2\n",
    "\n",
    "for i in range(len(testy_1)):\n",
    "    if (testy_1[i] > 2):\n",
    "        testy_1[i] = 2\n",
    "        \n",
    "for i in range(len(valy_1)):\n",
    "    if (valy_1[i] > 2):\n",
    "        valy_1[i] = 2\n",
    "\n",
    "### second data set ###\n",
    "\n",
    "for i in range(len(trainy_2)):\n",
    "    if (trainy_2[i] > 2):\n",
    "        trainy_2[i] = 2\n",
    "\n",
    "for i in range(len(testy_2)):\n",
    "    if (testy_2[i] > 2):\n",
    "        testy_2[i] = 2\n",
    "        \n",
    "for i in range(len(valy_2)):\n",
    "    if (valy_2[i] > 2):\n",
    "        valy_2[i] = 2\n",
    "        \n",
    "### third data set ###\n",
    "        \n",
    "for i in range(len(trainy_3)):\n",
    "    if (trainy_3[i] > 2):\n",
    "        trainy_3[i] = 2\n",
    "\n",
    "for i in range(len(testy_3)):\n",
    "    if (testy_3[i] > 2):\n",
    "        testy_3[i] = 2\n",
    "        \n",
    "for i in range(len(valy_3)):\n",
    "    if (valy_3[i] > 2):\n",
    "        valy_3[i] = 2\n",
    "        \n",
    "### forth data set ###\n",
    "        \n",
    "for i in range(len(trainy_4)):\n",
    "    if (trainy_4[i] > 2):\n",
    "        trainy_4[i] = 2\n",
    "\n",
    "for i in range(len(testy_4)):\n",
    "    if (testy_4[i] > 2):\n",
    "        testy_4[i] = 2\n",
    "        \n",
    "for i in range(len(valy_4)):\n",
    "    if (valy_4[i] > 2):\n",
    "        valy_4[i] = 2\n",
    "        \n",
    "### fifth data set ###\n",
    "        \n",
    "for i in range(len(trainy_5)):\n",
    "    if (trainy_5[i] > 2):\n",
    "        trainy_5[i] = 2\n",
    "\n",
    "for i in range(len(testy_5)):\n",
    "    if (testy_5[i] > 2):\n",
    "        testy_5[i] = 2\n",
    "        \n",
    "for i in range(len(valy_5)):\n",
    "    if (valy_5[i] > 2):\n",
    "        valy_5[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### decision trees ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now using the scklit lear library we train the descion tree model by injecting our data #\n",
    "from sklearn import tree\n",
    "\n",
    "clf_1 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=50)\n",
    "clf_1 = clf_1.fit(trainx_1, trainy_1)\n",
    "\n",
    "clf_2 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=50)\n",
    "clf_2 = clf_2.fit(trainx_2, trainy_2)\n",
    "\n",
    "clf_3 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=50)\n",
    "clf_3 = clf_3.fit(trainx_3, trainy_3)\n",
    "\n",
    "clf_4 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=50)\n",
    "clf_4 = clf_4.fit(trainx_4, trainy_4)\n",
    "\n",
    "clf_5 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=50)\n",
    "clf_5 = clf_5.fit(trainx_5, trainy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(x,y):\n",
    "    error_rate = np.mean(x != y)\n",
    "    print(f\"error rate is {error_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for data set 1\n",
      "error rate is 0.2\n",
      "for data set 2\n",
      "error rate is 0.24\n",
      "for data set 3\n",
      "error rate is 0.4897959183673469\n",
      "for data set 4\n",
      "error rate is 0.19230769230769232\n",
      "for data set 5\n",
      "error rate is 0.20430107526881722\n"
     ]
    }
   ],
   "source": [
    "# now we test the model using the test set #\n",
    "pred_1 = clf_1.predict(testx_1)\n",
    "pred_2 = clf_2.predict(testx_2)\n",
    "pred_3 = clf_3.predict(testx_3)\n",
    "pred_4 = clf_4.predict(testx_4)\n",
    "pred_5 = clf_5.predict(testx_5)\n",
    "\n",
    "print(\"for data set 1\")\n",
    "error_rate(pred_1,testy_1)\n",
    "\n",
    "print(\"for data set 2\")\n",
    "error_rate(pred_2,testy_2)\n",
    "\n",
    "print(\"for data set 3\")\n",
    "error_rate(pred_3,testy_3)\n",
    "\n",
    "print(\"for data set 4\")\n",
    "error_rate(pred_4,testy_4)\n",
    "\n",
    "print(\"for data set 5\")\n",
    "error_rate(pred_5,testy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(286.8290816326531, 358.04999999999995, 'X[16] <= 68.5\\nentropy = 0.903\\nsamples = 698\\nvalue = [559, 93, 46]'),\n",
       " Text(184.89285714285717, 334.95, 'X[8] <= 122.5\\nentropy = 0.561\\nsamples = 568\\nvalue = [507, 51, 10]'),\n",
       " Text(105.6530612244898, 311.84999999999997, 'X[13] <= 39.5\\nentropy = 0.394\\nsamples = 436\\nvalue = [406, 27, 3]'),\n",
       " Text(82.24489795918367, 288.75, 'X[1] <= 3.5\\nentropy = 0.369\\nsamples = 434\\nvalue = [406, 26, 2]'),\n",
       " Text(50.61224489795919, 265.65, 'X[6] <= 2.5\\nentropy = 0.24\\nsamples = 304\\nvalue = [293, 10, 1]'),\n",
       " Text(40.48979591836735, 242.54999999999998, 'X[10] <= 36.5\\nentropy = 0.345\\nsamples = 155\\nvalue = [145, 10, 0]'),\n",
       " Text(35.42857142857143, 219.45, 'X[6] <= 0.5\\nentropy = 0.429\\nsamples = 114\\nvalue = [104, 10, 0]'),\n",
       " Text(30.367346938775512, 196.35, 'entropy = 0.0\\nsamples = 34\\nvalue = [34, 0, 0]'),\n",
       " Text(40.48979591836735, 196.35, 'X[15] <= 18.5\\nentropy = 0.544\\nsamples = 80\\nvalue = [70, 10, 0]'),\n",
       " Text(35.42857142857143, 173.24999999999997, 'X[8] <= 35.5\\nentropy = 0.644\\nsamples = 61\\nvalue = [51, 10, 0]'),\n",
       " Text(25.306122448979593, 150.14999999999998, 'X[10] <= 35.5\\nentropy = 0.402\\nsamples = 50\\nvalue = [46, 4, 0]'),\n",
       " Text(20.244897959183675, 127.04999999999998, 'X[14] <= 3.5\\nentropy = 0.332\\nsamples = 49\\nvalue = [46, 3, 0]'),\n",
       " Text(15.183673469387756, 103.94999999999999, 'entropy = 0.0\\nsamples = 31\\nvalue = [31, 0, 0]'),\n",
       " Text(25.306122448979593, 103.94999999999999, 'X[2] <= 3.5\\nentropy = 0.65\\nsamples = 18\\nvalue = [15, 3, 0]'),\n",
       " Text(15.183673469387756, 80.84999999999997, 'X[2] <= 0.5\\nentropy = 0.371\\nsamples = 14\\nvalue = [13, 1, 0]'),\n",
       " Text(10.122448979591837, 57.75, 'X[0] <= 1.0\\nentropy = 1.0\\nsamples = 2\\nvalue = [1, 1, 0]'),\n",
       " Text(5.061224489795919, 34.64999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(15.183673469387756, 34.64999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(20.244897959183675, 57.75, 'entropy = 0.0\\nsamples = 12\\nvalue = [12, 0, 0]'),\n",
       " Text(35.42857142857143, 80.84999999999997, 'X[4] <= 21.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(30.367346938775512, 57.75, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(40.48979591836735, 57.75, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(30.367346938775512, 127.04999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(45.55102040816327, 150.14999999999998, 'X[13] <= 0.5\\nentropy = 0.994\\nsamples = 11\\nvalue = [5, 6, 0]'),\n",
       " Text(40.48979591836735, 127.04999999999998, 'X[0] <= 3.5\\nentropy = 0.592\\nsamples = 7\\nvalue = [1, 6, 0]'),\n",
       " Text(35.42857142857143, 103.94999999999999, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(45.55102040816327, 103.94999999999999, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(50.61224489795919, 127.04999999999998, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(45.55102040816327, 173.24999999999997, 'entropy = 0.0\\nsamples = 19\\nvalue = [19, 0, 0]'),\n",
       " Text(45.55102040816327, 219.45, 'entropy = 0.0\\nsamples = 41\\nvalue = [41, 0, 0]'),\n",
       " Text(60.734693877551024, 242.54999999999998, 'X[7] <= 122.5\\nentropy = 0.058\\nsamples = 149\\nvalue = [148, 0, 1]'),\n",
       " Text(55.673469387755105, 219.45, 'entropy = 0.0\\nsamples = 142\\nvalue = [142, 0, 0]'),\n",
       " Text(65.79591836734694, 219.45, 'X[3] <= 4.5\\nentropy = 0.592\\nsamples = 7\\nvalue = [6, 0, 1]'),\n",
       " Text(60.734693877551024, 196.35, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(70.85714285714286, 196.35, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(113.87755102040816, 265.65, 'X[10] <= 59.5\\nentropy = 0.602\\nsamples = 130\\nvalue = [113, 16, 1]'),\n",
       " Text(86.04081632653062, 242.54999999999998, 'X[10] <= 37.5\\nentropy = 1.124\\nsamples = 29\\nvalue = [18, 10, 1]'),\n",
       " Text(80.9795918367347, 219.45, 'entropy = 0.0\\nsamples = 11\\nvalue = [11, 0, 0]'),\n",
       " Text(91.10204081632654, 219.45, 'X[7] <= 7.0\\nentropy = 1.233\\nsamples = 18\\nvalue = [7, 10, 1]'),\n",
       " Text(80.9795918367347, 196.35, 'X[2] <= 1.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
       " Text(75.91836734693878, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(86.04081632653062, 173.24999999999997, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(101.22448979591837, 196.35, 'X[7] <= 48.0\\nentropy = 0.997\\nsamples = 15\\nvalue = [7, 8, 0]'),\n",
       " Text(96.16326530612245, 173.24999999999997, 'entropy = 0.0\\nsamples = 4\\nvalue = [4, 0, 0]'),\n",
       " Text(106.28571428571429, 173.24999999999997, 'X[7] <= 229.0\\nentropy = 0.845\\nsamples = 11\\nvalue = [3, 8, 0]'),\n",
       " Text(101.22448979591837, 150.14999999999998, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(111.34693877551021, 150.14999999999998, 'X[16] <= 21.0\\nentropy = 0.811\\nsamples = 4\\nvalue = [3, 1, 0]'),\n",
       " Text(106.28571428571429, 127.04999999999998, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(116.40816326530613, 127.04999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(141.71428571428572, 242.54999999999998, 'X[0] <= 6.5\\nentropy = 0.325\\nsamples = 101\\nvalue = [95, 6, 0]'),\n",
       " Text(136.65306122448982, 219.45, 'entropy = 0.0\\nsamples = 72\\nvalue = [72, 0, 0]'),\n",
       " Text(146.77551020408163, 219.45, 'X[13] <= 3.5\\nentropy = 0.736\\nsamples = 29\\nvalue = [23, 6, 0]'),\n",
       " Text(141.71428571428572, 196.35, 'X[7] <= 404.5\\nentropy = 0.605\\nsamples = 27\\nvalue = [23, 4, 0]'),\n",
       " Text(136.65306122448982, 173.24999999999997, 'X[15] <= 18.5\\nentropy = 0.402\\nsamples = 25\\nvalue = [23, 2, 0]'),\n",
       " Text(131.59183673469389, 150.14999999999998, 'X[4] <= 18.0\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(126.53061224489797, 127.04999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(136.65306122448982, 127.04999999999998, 'X[5] <= 3.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(131.59183673469389, 103.94999999999999, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(141.71428571428572, 103.94999999999999, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(141.71428571428572, 150.14999999999998, 'entropy = 0.0\\nsamples = 21\\nvalue = [21, 0, 0]'),\n",
       " Text(146.77551020408163, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(151.83673469387756, 196.35, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(129.06122448979593, 288.75, 'X[6] <= 221.0\\nentropy = 1.0\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(124.0, 265.65, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(134.12244897959184, 265.65, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(264.1326530612245, 311.84999999999997, 'X[9] <= 17.5\\nentropy = 0.967\\nsamples = 132\\nvalue = [101, 24, 7]'),\n",
       " Text(259.0714285714286, 288.75, 'X[11] <= 2.5\\nentropy = 1.144\\nsamples = 98\\nvalue = [67, 24, 7]'),\n",
       " Text(229.65306122448982, 265.65, 'X[13] <= 5.0\\nentropy = 1.178\\nsamples = 81\\nvalue = [52, 24, 5]'),\n",
       " Text(191.06122448979593, 242.54999999999998, 'X[6] <= 1.5\\nentropy = 1.027\\nsamples = 63\\nvalue = [41, 21, 1]'),\n",
       " Text(167.0204081632653, 219.45, 'X[7] <= 192.0\\nentropy = 0.485\\nsamples = 19\\nvalue = [17, 2, 0]'),\n",
       " Text(161.9591836734694, 196.35, 'entropy = 0.0\\nsamples = 15\\nvalue = [15, 0, 0]'),\n",
       " Text(172.08163265306123, 196.35, 'X[7] <= 391.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(167.0204081632653, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(177.14285714285717, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(215.10204081632654, 219.45, 'X[13] <= 1.5\\nentropy = 1.124\\nsamples = 44\\nvalue = [24, 19, 1]'),\n",
       " Text(192.3265306122449, 196.35, 'X[2] <= 4.5\\nentropy = 1.135\\nsamples = 18\\nvalue = [5, 12, 1]'),\n",
       " Text(187.26530612244898, 173.24999999999997, 'X[8] <= 205.5\\nentropy = 0.906\\nsamples = 15\\nvalue = [2, 12, 1]'),\n",
       " Text(182.20408163265307, 150.14999999999998, 'entropy = 0.0\\nsamples = 10\\nvalue = [0, 10, 0]'),\n",
       " Text(192.3265306122449, 150.14999999999998, 'X[16] <= 49.0\\nentropy = 1.522\\nsamples = 5\\nvalue = [2, 2, 1]'),\n",
       " Text(187.26530612244898, 127.04999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(197.38775510204084, 127.04999999999998, 'X[14] <= 2.0\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(192.3265306122449, 103.94999999999999, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(202.44897959183675, 103.94999999999999, 'X[9] <= 5.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(197.38775510204084, 80.84999999999997, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(207.51020408163265, 80.84999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(197.38775510204084, 173.24999999999997, 'entropy = 0.0\\nsamples = 3\\nvalue = [3, 0, 0]'),\n",
       " Text(237.8775510204082, 196.35, 'X[12] <= 2.5\\nentropy = 0.84\\nsamples = 26\\nvalue = [19, 7, 0]'),\n",
       " Text(232.81632653061226, 173.24999999999997, 'X[14] <= 5.5\\nentropy = 0.949\\nsamples = 19\\nvalue = [12, 7, 0]'),\n",
       " Text(222.69387755102042, 150.14999999999998, 'X[3] <= 10.5\\nentropy = 0.863\\nsamples = 7\\nvalue = [2, 5, 0]'),\n",
       " Text(217.63265306122452, 127.04999999999998, 'X[7] <= 67.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(212.57142857142858, 103.94999999999999, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(222.69387755102042, 103.94999999999999, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(227.75510204081633, 127.04999999999998, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 4, 0]'),\n",
       " Text(242.9387755102041, 150.14999999999998, 'X[10] <= 12.0\\nentropy = 0.65\\nsamples = 12\\nvalue = [10, 2, 0]'),\n",
       " Text(237.8775510204082, 127.04999999999998, 'X[6] <= 10.0\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(232.81632653061226, 103.94999999999999, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(242.9387755102041, 103.94999999999999, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(248.0, 127.04999999999998, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(242.9387755102041, 173.24999999999997, 'entropy = 0.0\\nsamples = 7\\nvalue = [7, 0, 0]'),\n",
       " Text(268.2448979591837, 242.54999999999998, 'X[1] <= 3.5\\nentropy = 1.347\\nsamples = 18\\nvalue = [11, 3, 4]'),\n",
       " Text(258.12244897959187, 219.45, 'X[8] <= 144.0\\nentropy = 0.863\\nsamples = 14\\nvalue = [10, 0, 4]'),\n",
       " Text(253.06122448979593, 196.35, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(263.18367346938777, 196.35, 'X[4] <= 13.5\\nentropy = 0.65\\nsamples = 12\\nvalue = [10, 0, 2]'),\n",
       " Text(258.12244897959187, 173.24999999999997, 'X[10] <= 12.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(253.06122448979593, 150.14999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(263.18367346938777, 150.14999999999998, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(268.2448979591837, 173.24999999999997, 'entropy = 0.0\\nsamples = 9\\nvalue = [9, 0, 0]'),\n",
       " Text(278.36734693877554, 219.45, 'X[14] <= 7.0\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 3, 0]'),\n",
       " Text(273.30612244897964, 196.35, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(283.42857142857144, 196.35, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(288.48979591836735, 265.65, 'X[0] <= 16.5\\nentropy = 0.523\\nsamples = 17\\nvalue = [15, 0, 2]'),\n",
       " Text(283.42857142857144, 242.54999999999998, 'entropy = 0.0\\nsamples = 14\\nvalue = [14, 0, 0]'),\n",
       " Text(293.55102040816325, 242.54999999999998, 'X[13] <= 1.0\\nentropy = 0.918\\nsamples = 3\\nvalue = [1, 0, 2]'),\n",
       " Text(288.48979591836735, 219.45, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(298.6122448979592, 219.45, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(269.1938775510204, 288.75, 'entropy = 0.0\\nsamples = 34\\nvalue = [34, 0, 0]'),\n",
       " Text(388.765306122449, 334.95, 'X[0] <= 15.5\\nentropy = 1.568\\nsamples = 130\\nvalue = [52, 42, 36]'),\n",
       " Text(334.0408163265306, 311.84999999999997, 'X[16] <= 287.0\\nentropy = 0.953\\nsamples = 38\\nvalue = [30, 4, 4]'),\n",
       " Text(323.9183673469388, 288.75, 'X[6] <= 37.0\\nentropy = 0.723\\nsamples = 33\\nvalue = [28, 4, 1]'),\n",
       " Text(318.8571428571429, 265.65, 'X[9] <= 12.5\\nentropy = 0.548\\nsamples = 31\\nvalue = [28, 2, 1]'),\n",
       " Text(313.795918367347, 242.54999999999998, 'X[12] <= 5.5\\nentropy = 1.096\\nsamples = 11\\nvalue = [8, 2, 1]'),\n",
       " Text(308.734693877551, 219.45, 'X[13] <= 0.5\\nentropy = 0.722\\nsamples = 10\\nvalue = [8, 2, 0]'),\n",
       " Text(303.6734693877551, 196.35, 'X[0] <= 9.0\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(298.6122448979592, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(308.734693877551, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(313.795918367347, 196.35, 'entropy = 0.0\\nsamples = 6\\nvalue = [6, 0, 0]'),\n",
       " Text(318.8571428571429, 219.45, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(323.9183673469388, 242.54999999999998, 'entropy = 0.0\\nsamples = 20\\nvalue = [20, 0, 0]'),\n",
       " Text(328.9795918367347, 265.65, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(344.16326530612247, 288.75, 'X[7] <= 96.0\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 0, 3]'),\n",
       " Text(339.10204081632656, 265.65, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(349.2244897959184, 265.65, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(443.48979591836735, 311.84999999999997, 'X[15] <= 389.5\\nentropy = 1.55\\nsamples = 92\\nvalue = [22, 38, 32]'),\n",
       " Text(406.16326530612247, 288.75, 'X[7] <= 23.5\\nentropy = 1.548\\nsamples = 79\\nvalue = [22, 35, 22]'),\n",
       " Text(359.34693877551024, 265.65, 'X[14] <= 3.5\\nentropy = 1.359\\nsamples = 31\\nvalue = [13, 15, 3]'),\n",
       " Text(346.6938775510204, 242.54999999999998, 'X[1] <= 1.5\\nentropy = 1.449\\nsamples = 7\\nvalue = [1, 3, 3]'),\n",
       " Text(341.6326530612245, 219.45, 'X[12] <= 17.0\\nentropy = 0.811\\nsamples = 4\\nvalue = [1, 0, 3]'),\n",
       " Text(336.5714285714286, 196.35, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(346.6938775510204, 196.35, 'entropy = 0.0\\nsamples = 1\\nvalue = [1, 0, 0]'),\n",
       " Text(351.7551020408163, 219.45, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(372.0, 242.54999999999998, 'X[9] <= 21.5\\nentropy = 1.0\\nsamples = 24\\nvalue = [12, 12, 0]'),\n",
       " Text(361.8775510204082, 219.45, 'X[14] <= 8.0\\nentropy = 0.684\\nsamples = 11\\nvalue = [2, 9, 0]'),\n",
       " Text(356.8163265306123, 196.35, 'X[13] <= 7.0\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 2, 0]'),\n",
       " Text(351.7551020408163, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(361.8775510204082, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(366.9387755102041, 196.35, 'entropy = 0.0\\nsamples = 7\\nvalue = [0, 7, 0]'),\n",
       " Text(382.12244897959187, 219.45, 'X[15] <= 248.0\\nentropy = 0.779\\nsamples = 13\\nvalue = [10, 3, 0]'),\n",
       " Text(377.06122448979596, 196.35, 'entropy = 0.0\\nsamples = 8\\nvalue = [8, 0, 0]'),\n",
       " Text(387.18367346938777, 196.35, 'X[8] <= 822.5\\nentropy = 0.971\\nsamples = 5\\nvalue = [2, 3, 0]'),\n",
       " Text(382.12244897959187, 173.24999999999997, 'X[1] <= 1.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [2, 1, 0]'),\n",
       " Text(377.06122448979596, 150.14999999999998, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(387.18367346938777, 150.14999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(392.2448979591837, 173.24999999999997, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
       " Text(452.9795918367347, 265.65, 'X[15] <= 235.5\\nentropy = 1.508\\nsamples = 48\\nvalue = [9, 20, 19]'),\n",
       " Text(435.26530612244903, 242.54999999999998, 'X[9] <= 32.5\\nentropy = 1.554\\nsamples = 37\\nvalue = [9, 13, 15]'),\n",
       " Text(425.14285714285717, 219.45, 'X[7] <= 402.0\\nentropy = 1.425\\nsamples = 31\\nvalue = [4, 13, 14]'),\n",
       " Text(420.08163265306126, 196.35, 'X[8] <= 672.5\\nentropy = 1.447\\nsamples = 27\\nvalue = [4, 13, 10]'),\n",
       " Text(407.42857142857144, 173.24999999999997, 'X[7] <= 389.0\\nentropy = 1.302\\nsamples = 23\\nvalue = [2, 13, 8]'),\n",
       " Text(397.30612244897964, 150.14999999999998, 'X[15] <= 72.5\\nentropy = 0.949\\nsamples = 19\\nvalue = [0, 12, 7]'),\n",
       " Text(392.2448979591837, 127.04999999999998, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(402.36734693877554, 127.04999999999998, 'X[16] <= 92.5\\nentropy = 0.874\\nsamples = 17\\nvalue = [0, 12, 5]'),\n",
       " Text(397.30612244897964, 103.94999999999999, 'entropy = 0.0\\nsamples = 5\\nvalue = [0, 5, 0]'),\n",
       " Text(407.42857142857144, 103.94999999999999, 'X[7] <= 58.5\\nentropy = 0.98\\nsamples = 12\\nvalue = [0, 7, 5]'),\n",
       " Text(402.36734693877554, 80.84999999999997, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(412.48979591836735, 80.84999999999997, 'X[5] <= 3.0\\nentropy = 0.991\\nsamples = 9\\nvalue = [0, 4, 5]'),\n",
       " Text(407.42857142857144, 57.75, 'X[14] <= 12.0\\nentropy = 0.918\\nsamples = 6\\nvalue = [0, 4, 2]'),\n",
       " Text(402.36734693877554, 34.64999999999998, 'X[14] <= 3.5\\nentropy = 0.918\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
       " Text(397.30612244897964, 11.550000000000011, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(407.42857142857144, 11.550000000000011, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(412.48979591836735, 34.64999999999998, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(417.5510204081633, 57.75, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(417.5510204081633, 150.14999999999998, 'X[15] <= 132.0\\nentropy = 1.5\\nsamples = 4\\nvalue = [2, 1, 1]'),\n",
       " Text(412.48979591836735, 127.04999999999998, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(422.6122448979592, 127.04999999999998, 'X[1] <= 4.0\\nentropy = 1.0\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(417.5510204081633, 103.94999999999999, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(427.6734693877551, 103.94999999999999, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(432.734693877551, 173.24999999999997, 'X[16] <= 209.5\\nentropy = 1.0\\nsamples = 4\\nvalue = [2, 0, 2]'),\n",
       " Text(427.6734693877551, 150.14999999999998, 'entropy = 0.0\\nsamples = 2\\nvalue = [2, 0, 0]'),\n",
       " Text(437.795918367347, 150.14999999999998, 'entropy = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
       " Text(430.2040816326531, 196.35, 'entropy = 0.0\\nsamples = 4\\nvalue = [0, 0, 4]'),\n",
       " Text(445.38775510204084, 219.45, 'X[14] <= 39.5\\nentropy = 0.65\\nsamples = 6\\nvalue = [5, 0, 1]'),\n",
       " Text(440.32653061224494, 196.35, 'entropy = 0.0\\nsamples = 5\\nvalue = [5, 0, 0]'),\n",
       " Text(450.44897959183675, 196.35, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(470.6938775510204, 242.54999999999998, 'X[11] <= 4.5\\nentropy = 0.946\\nsamples = 11\\nvalue = [0, 7, 4]'),\n",
       " Text(465.6326530612245, 219.45, 'X[12] <= 0.5\\nentropy = 0.544\\nsamples = 8\\nvalue = [0, 7, 1]'),\n",
       " Text(460.5714285714286, 196.35, 'X[8] <= 782.0\\nentropy = 1.0\\nsamples = 2\\nvalue = [0, 1, 1]'),\n",
       " Text(455.51020408163265, 173.24999999999997, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
       " Text(465.6326530612245, 173.24999999999997, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
       " Text(470.6938775510204, 196.35, 'entropy = 0.0\\nsamples = 6\\nvalue = [0, 6, 0]'),\n",
       " Text(475.7551020408164, 219.45, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
       " Text(480.8163265306123, 288.75, 'X[10] <= 26.0\\nentropy = 0.779\\nsamples = 13\\nvalue = [0, 3, 10]'),\n",
       " Text(475.7551020408164, 265.65, 'entropy = 0.0\\nsamples = 9\\nvalue = [0, 0, 9]'),\n",
       " Text(485.8775510204082, 265.65, 'X[2] <= 30.0\\nentropy = 0.811\\nsamples = 4\\nvalue = [0, 3, 1]'),\n",
       " Text(480.8163265306123, 242.54999999999998, 'entropy = 0.0\\nsamples = 3\\nvalue = [0, 3, 0]'),\n",
       " Text(490.9387755102041, 242.54999999999998, 'entropy = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we plot the resulting tree #\n",
    "\n",
    "tree.plot_tree(clf_1.fit(trainx_1, trainy_1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now using the scklit lear library we train the logistic regression model by injecting our data #\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr_1 = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=10000)\n",
    "logisticRegr_1.fit(trainx_1, trainy_1)\n",
    "\n",
    "logisticRegr_2 = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=10000)\n",
    "logisticRegr_2.fit(trainx_2, trainy_2)\n",
    "\n",
    "logisticRegr_3 = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=10000)\n",
    "logisticRegr_3.fit(trainx_3, trainy_3)\n",
    "\n",
    "logisticRegr_4 = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=10000)\n",
    "logisticRegr_4.fit(trainx_4, trainy_4)\n",
    "\n",
    "logisticRegr_5 = LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=10000)\n",
    "logisticRegr_5.fit(trainx_5, trainy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we test the model using the test set #\n",
    "\n",
    "pred_1 = logisticRegr_1.predict(testx_1)\n",
    "pred_2 = logisticRegr_2.predict(testx_2)\n",
    "pred_3 = logisticRegr_3.predict(testx_3)\n",
    "pred_4 = logisticRegr_4.predict(testx_4)\n",
    "pred_5 = logisticRegr_5.predict(testx_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for data set 1\n",
      "the model is 0.8266666666666667 accurate\n",
      "error rate is 0.17333333333333334\n",
      "for data set 2\n",
      "the model is 0.8177777777777778 accurate\n",
      "error rate is 0.18222222222222223\n",
      "for data set 3\n",
      "the model is 0.5918367346938775 accurate\n",
      "error rate is 0.40816326530612246\n",
      "for data set 4\n",
      "the model is 0.8461538461538461 accurate\n",
      "error rate is 0.15384615384615385\n",
      "for data set 5\n",
      "the model is 0.8745519713261649 accurate\n",
      "error rate is 0.12544802867383512\n"
     ]
    }
   ],
   "source": [
    "score = logisticRegr_1.score(testx_1, testy_1)\n",
    "print(\"for data set 1\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_1,testy_1)\n",
    "\n",
    "score = logisticRegr_2.score(testx_2, testy_2)\n",
    "print(\"for data set 2\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_2,testy_2)\n",
    "\n",
    "score = logisticRegr_3.score(testx_3, testy_3)\n",
    "print(\"for data set 3\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_3,testy_3)\n",
    "\n",
    "score = logisticRegr_4.score(testx_4, testy_4)\n",
    "print(\"for data set 4\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_4,testy_4)\n",
    "\n",
    "score = logisticRegr_5.score(testx_5, testy_5)\n",
    "print(\"for data set 5\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_5,testy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### multiclassfier ###\n",
    "### SVM ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.svm import SVC\n",
    "\n",
    "svm_1 = SVC(gamma='auto')\n",
    "svm_1.fit(trainx_1, trainy_1)\n",
    "\n",
    "svm_2 = SVC(gamma='auto')\n",
    "svm_2.fit(trainx_2, trainy_2)\n",
    "\n",
    "svm_3 = SVC(gamma='auto')\n",
    "svm_3.fit(trainx_3, trainy_3)\n",
    "\n",
    "svm_4 = SVC(gamma='auto')\n",
    "svm_4.fit(trainx_4, trainy_4)\n",
    "\n",
    "svm_5 = SVC(gamma='auto')\n",
    "svm_5.fit(trainx_5, trainy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1C = svm_1.predict(testx_1)\n",
    "pred_2C = svm_2.predict(testx_2)\n",
    "pred_3C = svm_3.predict(testx_3)\n",
    "pred_4C = svm_4.predict(testx_4)\n",
    "pred_5C = svm_5.predict(testx_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for data set 1\n",
      "the model is 0.8 accurate\n",
      "error rate is 0.2\n",
      "for data set 2\n",
      "the model is 0.8444444444444444 accurate\n",
      "error rate is 0.15555555555555556\n",
      "for data set 3\n",
      "the model is 0.5306122448979592 accurate\n",
      "error rate is 0.46938775510204084\n",
      "for data set 4\n",
      "the model is 0.8461538461538461 accurate\n",
      "error rate is 0.15384615384615385\n",
      "for data set 5\n",
      "the model is 0.8960573476702509 accurate\n",
      "error rate is 0.1039426523297491\n"
     ]
    }
   ],
   "source": [
    "score = svm_1.score(testx_1, testy_1)\n",
    "print(\"for data set 1\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_1C,testy_1)\n",
    "\n",
    "score = svm_2.score(testx_2, testy_2)\n",
    "print(\"for data set 2\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_2C,testy_2)\n",
    "\n",
    "score = svm_3.score(testx_3, testy_3)\n",
    "print(\"for data set 3\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_3C,testy_3)\n",
    "\n",
    "score = svm_4.score(testx_4, testy_4)\n",
    "print(\"for data set 4\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_4C,testy_4)\n",
    "\n",
    "score = svm_5.score(testx_5, testy_5)\n",
    "print(\"for data set 5\")\n",
    "print(f\"the model is {score} accurate\")\n",
    "error_rate(pred_5C,testy_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "›"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
